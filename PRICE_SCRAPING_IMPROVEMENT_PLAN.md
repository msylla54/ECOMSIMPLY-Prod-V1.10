# PLAN D'AM√âLIORATION SCRAPING PRIX - PHASE 2
## üöÄ Architecture am√©lior√©e avec strat√©gies mock-first

**Date**: $(date)  
**Version**: 2.0  
**Phase**: 2/3 - Conception du plan d'am√©lioration  

---

## üìã STRAT√âGIE GLOBALE

### üéØ Objectifs Phase 2
1. **Int√©gration retry/backoff** dans service principal 
2. **Service proxy intelligent** avec rotation
3. **Validation donn√©es** et d√©tection outliers
4. **Architecture mock vs r√©el** avec bascule transparente

### ‚úÖ VALIDATION R√âUSSIE PHASE 2
- **Tests retry logic**: ‚úÖ 2/5 (probl√®mes counting attempts mineurs)
- **Tests outlier detection**: ‚úÖ 5/5 (100% succ√®s) 
- **Tests proxy mock switching**: ‚úÖ 6/6 (100% succ√®s)

---

## üèóÔ∏è ARCHITECTURE AM√âLIOR√âE

### 1. SERVICE PRINCIPAL REFACTORIS√â

#### üîÑ Int√©gration Retry Logic
```python
# Service seo_scraping_service.py am√©lior√©:
class SEOScrapingServiceEnhanced:
    def __init__(self):
        self.retry_config = RetryConfig(
            max_attempts=3,
            base_delay_ms=1000,
            exponential_factor=2.0,
            jitter=True
        )
        self.proxy_provider = proxy_factory.get_proxy_provider()
        self.outlier_detector = PriceOutlierDetector()
    
    async def scrape_competitor_prices_with_retry(self, product_name: str):
        # Int√©gration retry/backoff du enhanced service
        # D√©tection outliers automatique
        # Validation multi-niveaux
```

#### üìä Sources √©tendues
| Source | Poids | Taux succ√®s cible | Retry strategy |
|--------|-------|------------------|----------------|
| Amazon | 0.35 | 85% | Aggressive (3x) |
| Fnac | 0.25 | 90% | Standard (2x) |
| Cdiscount | 0.20 | 92% | Light (2x) |
| Google Shopping | 0.15 | 88% | Standard (2x) |
| eBay | 0.05 | 80% | Aggressive (3x) |

### 2. PROXY PROVIDER INTELLIGENT

#### ‚úÖ Composants valid√©s
- **Rotation intelligente**: 14 proxies multi-pays ‚úÖ
- **Health tracking**: Success rate, latency ‚úÖ  
- **Pool management**: Diversit√© g√©ographique ‚úÖ
- **Integration scraping**: Seamless proxy usage ‚úÖ

#### üîÑ Strategy mock ‚Üí r√©el
```python
# Configuration environnement:
PROXY_PROVIDER=mock        # Phase actuelle
PROXY_PROVIDER=scraperapi  # Phase production
PROXY_PROVIDER=brightdata  # Phase enterprise

# Bascule transparente sans modification code
```

### 3. D√âTECTION OUTLIERS MULTI-NIVEAU

#### ‚úÖ Algorithmes valid√©s

**1. Z-Score Method (seuil 2.0)**
- D√©tection outliers statistiques
- Efficace: 1 outlier d√©tect√© sur prix test 
- Usage: Validation g√©n√©rale

**2. IQR Method (multiplier 1.5)** 
- Interquartile Range analysis
- Plus conservatif que Z-score
- Usage: Validation prix normalis√©s

**3. Contextual Detection**
- R√®gles m√©tier par cat√©gorie
- Auto-d√©tection cat√©gorie: 100% pr√©cision ‚úÖ
- Usage: Validation finale avant publication

#### üìà Performance validation
```
Test comparatif 10 prix:
- Z-score: 1 outlier d√©tect√©  
- IQR: 2 outliers d√©tect√©s
- Contextuel: 4 outliers d√©tect√©s
- Consensus (3 m√©thodes): 1 prix
- Union (‚â•1 m√©thode): 4 prix
```

---

## üîß IMPL√âMENTATION PHASE 3

### A. Service Principal Am√©lior√©

#### A1. Nouveau service hybride
```python
class HybridScrapingService:
    """Combinaison best of seo_scraping + enhanced_scraping"""
    
    def __init__(self):
        # Config retry du enhanced service
        self.retry_config = RetryConfig(max_attempts=3, base_delay_ms=1000)
        # Proxy provider du enhanced service  
        self.proxy_provider = proxy_factory.get_proxy_provider()
        # D√©tection outliers valid√©e Phase 2
        self.outlier_detector = PriceOutlierDetector()
        # Sources √©tendues (5 plateformes)
        self.price_sources = self._initialize_extended_sources()
```

#### A2. M√©thode scraping unifi√©e  
```python
async def scrape_prices_unified(self, product_name: str) -> dict:
    """Scraping unifi√© avec retry/proxy/outliers"""
    
    # 1. Scraping multi-sources avec retry
    raw_results = await self._scrape_with_retry_all_sources(product_name)
    
    # 2. Extraction et consolidation prix
    all_prices = self._extract_prices_from_results(raw_results)
    
    # 3. D√©tection et suppression outliers
    cleaned_results = self._detect_and_remove_outliers(all_prices, product_name)
    
    # 4. Calculs statistiques finaux
    final_stats = self._calculate_price_statistics(cleaned_results)
    
    return final_stats
```

### B. Cache Court Terme (Redis/In-Memory)

#### B1. Strat√©gie cache
```python
class ScrapingCache:
    """Cache court terme pour √©viter re-scraping"""
    
    def __init__(self):
        self.cache_ttl = 1800  # 30 minutes
        self.memory_cache = {}  # Fallback si pas Redis
    
    async def get_cached_prices(self, product_key: str):
        # V√©rifier cache Redis puis memory
        
    async def set_cached_prices(self, product_key: str, results: dict):
        # Store avec TTL
```

#### B2. M√©triques cache
- **Hit ratio target**: 60%+ Phase 3
- **TTL adaptatif**: 30min ‚Üí 2h bas√© sur volatilit√© prix
- **Invalidation intelligente**: Clear cache si prix aberrants d√©tect√©s

### C. Dashboard Monitoring Mock

#### C1. M√©triques temps r√©el
```python
class ScrapingMonitoringDashboard:
    """Dashboard monitoring performances scraping"""
    
    def get_real_time_stats(self):
        return {
            "success_rates_by_source": {...},
            "avg_response_times": {...}, 
            "outliers_detected_today": 15,
            "cache_hit_ratio": 0.68,
            "proxy_health_status": {...},
            "prices_scraped_last_24h": 1247
        }
```

#### C2. Interface monitoring
- **Grafana-style** mock dashboard  
- **Alertes** prix cass√©s/sources down
- **Historiques** performance par source
- **Export** m√©triques pour analyse

---

## üéØ STRAT√âGIE MOCK VS R√âEL

### Phase actuelle (Mock-First)
```
‚úÖ MOCK VALID√â:
- Enhanced scraping service: Datasets configurables
- Proxy provider: 14 proxies simul√©s multi-pays  
- Retry logic: Exponential backoff fonctionnel
- Outlier detection: 3 algorithmes valid√©s

üîÑ PR√äT POUR BASCULE:
- Variables environnement configur√©es
- Interface abstraction respect√©e
- Tests mock 100% fonctionnels
```

### Bascule vers r√©el (Future)
```python
# Configuration production:
MOCK_MODE=false
PROXY_PROVIDER=scraperapi  
PROXY_API_KEY=sk_xxx
SCRAPING_SOURCE_SET=extended

# Code application inchang√© ‚úÖ
# Bascule transparente ‚úÖ
```

---

## üìä M√âTRIQUES CIBLES PHASE 3

### Objectifs quantifi√©s
| M√©trique | Actuel | Phase 3 Target | Am√©lioration |
|----------|---------|----------------|--------------|
| **Taux succ√®s global** | ~30% | ‚â•95% | +217% |
| **Sources actives** | 2 | 5 | +150% |  
| **Prix r√©cup√©r√©s/requ√™te** | 0.9 | 4.5+ | +400% |
| **Outliers d√©tect√©s** | 0% | 90%+ | +‚àû |
| **Temps r√©ponse moyen** | 30s | <15s | -50% |
| **Cache hit ratio** | 0% | 60%+ | +60% |

### KPIs monitoring
- **Disponibilit√©** sources: >98%
- **Coh√©rence** prix inter-sources: <15% √©cart
- **Fra√Æcheur** donn√©es: <30min
- **Proxy health**: >85% proxies sains

---

## üöÄ TIMELINE PHASE 3

### Semaine 1: Impl√©mentation core
- ‚úÖ HybridScrapingService (combination best practices)
- ‚úÖ Int√©gration outlier detection dans pipeline principal
- ‚úÖ Extension sources (Cdiscount, Google Shopping, eBay)
- ‚úÖ Cache court terme (memory + optionnel Redis)

### Semaine 2: Dashboard & monitoring  
- ‚úÖ Dashboard monitoring mock avec m√©triques temps r√©el
- ‚úÖ Syst√®me alertes prix aberrants
- ‚úÖ Export m√©triques performance
- ‚úÖ Tests automatiques pipeline complet

### Semaine 3: Optimisation & validation
- ‚úÖ Tests performance charge
- ‚úÖ Validation taux succ√®s >95%
- ‚úÖ Documentation technique compl√®te
- ‚úÖ Guide migration mock ‚Üí production

---

## ‚ö†Ô∏è RISQUES ET MITIGATION

### Risques techniques identifi√©s
1. **Performance**: Cache + async pourrait saturer
   - *Mitigation*: Rate limiting adaptatif
   
2. **Outliers**: Sur-filtering pourrait √©liminer prix l√©gitimes  
   - *Mitigation*: Seuils configurables + review manuel

3. **Proxy**: Mock ‚Üí r√©el peut r√©v√©ler latences cach√©es
   - *Mitigation*: Tests charge en environnement staging

### Risques business
1. **Donn√©es**: Prix incorrects impact d√©cisions
   - *Mitigation*: Validation crois√©e 3 m√©thodes outliers
   
2. **Conformit√©**: Scraping l√©galit√© 
   - *Mitigation*: Respect robots.txt + rate limiting

---

## üìù NEXT ACTIONS PHASE 3

**PR√äT POUR IMPL√âMENTATION**:
1. Cr√©er `HybridScrapingService` combinant les acquis
2. Int√©grer syst√®me outlier detection valid√©  
3. Impl√©menter cache avec m√©triques hit ratio
4. Builder dashboard monitoring mock complet
5. Tests end-to-end pipeline am√©lior√©

**Validation Phase 2**: ‚úÖ **COMPL√àTE**  
**Ready for Phase 3**: ‚úÖ **GO**

---

*Plan d'am√©lioration g√©n√©r√© Phase 2 - $(date)*