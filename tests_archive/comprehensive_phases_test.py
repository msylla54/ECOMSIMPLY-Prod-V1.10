#!/usr/bin/env python3
"""
ECOMSIMPLY COMPREHENSIVE PHASES TESTING - SYST√àME COMPLET 6 PHASES
Test global de toutes les phases d'am√©lioration du syst√®me de g√©n√©ration de fiches produits avec mode QA.

PHASES √Ä TESTER:
- Phase 1: Services modulaires fonctionnels
- Phase 2: Logging structur√© actif
- Phase 3: Validation avanc√©e des entr√©es
- Phase 4: Champs fallback (model_used, generation_method, fallback_level)
- Phase 5: Enrichissement SEO (seo_tags_source)
- Phase 6: Mode QA (qa_test_mode, qa_simulation_triggered)

TESTS SP√âCIFIQUES:
1. TEST MODE QA ACTIV√â avec TEST_MODE=True
2. G√©n√©ration de 10 fiches produits diff√©rentes
3. V√©rification qu'au moins 1 g√©n√©ration d√©clenche un fallback simul√©
4. Test endpoint QA statistics
5. Test complet g√©n√©ration MacBook Pro M3 2024
"""

import asyncio
import aiohttp
import json
import time
import os
import random
from typing import Dict, List, Any

# Backend URL from environment
BACKEND_URL = "https://ecomsimply.com/api"

class ComprehensivePhasesQATester:
    def __init__(self):
        self.session = None
        self.test_results = []
        self.test_user = None
        self.qa_mode_enabled = False
        self.generation_results = []
        
    async def setup_session(self):
        """Setup HTTP session"""
        self.session = aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=120)
        )
        print("‚úÖ Session HTTP initialis√©e pour tests QA")
        return True
    
    async def cleanup(self):
        """Cleanup HTTP session"""
        if self.session:
            await self.session.close()
    
    def get_auth_headers(self, token: str):
        """Get authorization headers"""
        return {"Authorization": f"Bearer {token}"}
    
    async def create_test_user(self) -> Dict:
        """Create a test user for QA testing"""
        
        user_data = {
            "email": f"qa_test_{int(time.time())}@ecomsimply.test",
            "name": "QA Test User",
            "password": "QATestPassword123!"
        }
        
        print(f"üë§ Cr√©ation utilisateur QA test...")
        
        try:
            # Register user
            async with self.session.post(f"{BACKEND_URL}/auth/register", json=user_data) as response:
                if response.status == 200:
                    register_result = await response.json()
                    print(f"‚úÖ Utilisateur QA cr√©√©: {user_data['email']}")
                    
                    # Login to get token
                    login_data = {
                        "email": user_data["email"],
                        "password": user_data["password"]
                    }
                    
                    async with self.session.post(f"{BACKEND_URL}/auth/login", json=login_data) as login_response:
                        if login_response.status == 200:
                            login_result = await login_response.json()
                            token = login_result.get("token")
                            
                            user_info = {
                                "email": user_data["email"],
                                "token": token,
                                "plan": "gratuit"
                            }
                            
                            self.test_user = user_info
                            print(f"‚úÖ Utilisateur QA pr√™t avec token")
                            return user_info
                        else:
                            error_text = await login_response.text()
                            print(f"‚ùå √âchec login QA: {login_response.status} - {error_text}")
                            return None
                else:
                    error_text = await response.text()
                    print(f"‚ùå √âchec cr√©ation utilisateur QA: {response.status} - {error_text}")
                    return None
                    
        except Exception as e:
            print(f"‚ùå Exception cr√©ation utilisateur QA: {str(e)}")
            return None
    
    async def test_qa_mode_activation(self):
        """
        TEST 1: MODE QA ACTIV√â
        V√©rifier que le mode QA peut √™tre activ√© et fonctionne
        """
        print("\nüß™ TEST 1: MODE QA ACTIV√â")
        print("=" * 60)
        
        if not self.test_user:
            user_info = await self.create_test_user()
            if not user_info:
                print("‚ùå Impossible de cr√©er l'utilisateur QA")
                return False
        
        # Test avec mode QA activ√© via param√®tre ou variable d'environnement
        test_product = {
            "product_name": "iPhone 15 Pro QA Test",
            "product_description": "Test du mode QA avec iPhone 15 Pro pour v√©rifier les fallbacks",
            "generate_image": True,
            "number_of_images": 1,
            "language": "fr",
            "category": "√©lectronique",
            "qa_test_mode": True  # Activation explicite du mode QA
        }
        
        print(f"üî• Test mode QA avec: {test_product['product_name']}")
        
        try:
            start_time = time.time()
            
            async with self.session.post(
                f"{BACKEND_URL}/generate-sheet",
                json=test_product,
                headers=self.get_auth_headers(self.test_user["token"])
            ) as response:
                
                generation_time = time.time() - start_time
                status = response.status
                
                if status == 200:
                    result = await response.json()
                    
                    # V√©rification des champs QA sp√©cifiques
                    qa_fields = {
                        "qa_test_mode": result.get("qa_test_mode"),
                        "qa_simulation_triggered": result.get("qa_simulation_triggered"),
                        "model_used": result.get("model_used"),
                        "generation_method": result.get("generation_method"),
                        "fallback_level": result.get("fallback_level"),
                        "seo_tags_source": result.get("seo_tags_source")
                    }
                    
                    print(f"‚úÖ G√âN√âRATION QA R√âUSSIE en {generation_time:.2f}s")
                    print(f"   ü§ñ Mode QA: {qa_fields['qa_test_mode']}")
                    print(f"   ‚ö° Simulation d√©clench√©e: {qa_fields['qa_simulation_triggered']}")
                    print(f"   üß† Mod√®le utilis√©: {qa_fields['model_used']}")
                    print(f"   üîß M√©thode g√©n√©ration: {qa_fields['generation_method']}")
                    print(f"   üìä Niveau fallback: {qa_fields['fallback_level']}")
                    print(f"   üè∑Ô∏è Source SEO tags: {qa_fields['seo_tags_source']}")
                    
                    # Validation des phases
                    phase_validation = {
                        "Phase 1 - Services modulaires": len(result.get('generated_images', [])) > 0 and len(result.get('key_features', [])) >= 5,
                        "Phase 2 - Logging structur√©": result.get('generation_time') is not None,
                        "Phase 3 - Validation entr√©es": len(result.get('generated_title', '')) > 0,
                        "Phase 4 - Champs fallback": qa_fields['model_used'] is not None,
                        "Phase 5 - Enrichissement SEO": qa_fields['seo_tags_source'] is not None,
                        "Phase 6 - Mode QA": qa_fields['qa_test_mode'] is not None
                    }
                    
                    print(f"\nüìã VALIDATION DES 6 PHASES:")
                    for phase, validated in phase_validation.items():
                        status_icon = "‚úÖ" if validated else "‚ùå"
                        print(f"   {status_icon} {phase}")
                    
                    self.test_results.append({
                        "test": "qa_mode_activation",
                        "success": True,
                        "generation_time": generation_time,
                        "qa_fields": qa_fields,
                        "phase_validation": phase_validation,
                        "phases_passed": sum(phase_validation.values()),
                        "total_phases": len(phase_validation)
                    })
                    
                    self.qa_mode_enabled = qa_fields.get('qa_test_mode', False)
                    return True
                else:
                    error_text = await response.text()
                    print(f"‚ùå ERREUR MODE QA: {status} - {error_text}")
                    self.test_results.append({
                        "test": "qa_mode_activation",
                        "success": False,
                        "error": f"HTTP {status}: {error_text[:200]}"
                    })
                    return False
                    
        except Exception as e:
            print(f"‚ùå EXCEPTION MODE QA: {str(e)}")
            self.test_results.append({
                "test": "qa_mode_activation",
                "success": False,
                "error": str(e)
            })
            return False
    
    async def test_multiple_generations_qa(self):
        """
        TEST 2: G√âN√âRATION DE 10 FICHES PRODUITS DIFF√âRENTES
        V√©rifier qu'au moins 1 g√©n√©ration d√©clenche un fallback simul√©
        """
        print("\nüß™ TEST 2: G√âN√âRATION MULTIPLE AVEC QA")
        print("=" * 60)
        
        if not self.test_user:
            print("‚ùå Utilisateur QA non disponible")
            return False
        
        # 10 produits diff√©rents pour tester la vari√©t√©
        test_products = [
            {"name": "MacBook Pro M3 2024", "desc": "Ordinateur portable Apple avec puce M3 pour professionnels", "cat": "√©lectronique"},
            {"name": "iPhone 15 Pro Max", "desc": "Smartphone Apple haut de gamme avec appareil photo 48MP", "cat": "√©lectronique"},
            {"name": "Nike Air Max 270", "desc": "Chaussures de sport Nike avec technologie Air Max", "cat": "sport"},
            {"name": "Samsung Galaxy S24 Ultra", "desc": "Smartphone Samsung avec S Pen et √©cran 6.8 pouces", "cat": "√©lectronique"},
            {"name": "Sony WH-1000XM5", "desc": "Casque audio sans fil avec r√©duction de bruit active", "cat": "√©lectronique"},
            {"name": "Adidas Ultraboost 22", "desc": "Chaussures de running Adidas avec technologie Boost", "cat": "sport"},
            {"name": "iPad Pro 12.9 M2", "desc": "Tablette Apple avec √©cran Liquid Retina XDR", "cat": "√©lectronique"},
            {"name": "Nintendo Switch OLED", "desc": "Console de jeu portable Nintendo avec √©cran OLED", "cat": "√©lectronique"},
            {"name": "AirPods Pro 2", "desc": "√âcouteurs sans fil Apple avec r√©duction de bruit", "cat": "√©lectronique"},
            {"name": "Tesla Model 3", "desc": "Voiture √©lectrique Tesla avec autopilot", "cat": "auto"}
        ]
        
        fallback_triggered_count = 0
        successful_generations = 0
        
        print(f"üî• Test de {len(test_products)} g√©n√©rations avec mode QA")
        
        for i, product in enumerate(test_products, 1):
            print(f"\nüì± G√©n√©ration {i}/10: {product['name']}")
            
            test_request = {
                "product_name": product["name"],
                "product_description": product["desc"],
                "generate_image": True,
                "number_of_images": 1,
                "language": "fr",
                "category": product["cat"],
                "qa_test_mode": True
            }
            
            try:
                start_time = time.time()
                
                async with self.session.post(
                    f"{BACKEND_URL}/generate-sheet",
                    json=test_request,
                    headers=self.get_auth_headers(self.test_user["token"])
                ) as response:
                    
                    generation_time = time.time() - start_time
                    
                    if response.status == 200:
                        result = await response.json()
                        successful_generations += 1
                        
                        # V√©rifier si un fallback a √©t√© d√©clench√©
                        qa_simulation = result.get("qa_simulation_triggered", False)
                        fallback_level = result.get("fallback_level", 0)
                        
                        if qa_simulation or (fallback_level and fallback_level > 1):
                            fallback_triggered_count += 1
                            print(f"   ‚ö° FALLBACK D√âTECT√â! (Simulation: {qa_simulation}, Niveau: {fallback_level})")
                        else:
                            print(f"   ‚úÖ G√©n√©ration normale (Temps: {generation_time:.1f}s)")
                        
                        # Stocker les r√©sultats pour analyse
                        self.generation_results.append({
                            "product": product["name"],
                            "success": True,
                            "generation_time": generation_time,
                            "qa_simulation_triggered": qa_simulation,
                            "fallback_level": fallback_level,
                            "model_used": result.get("model_used"),
                            "seo_tags_source": result.get("seo_tags_source")
                        })
                        
                    else:
                        error_text = await response.text()
                        print(f"   ‚ùå Erreur: {response.status} - {error_text[:100]}")
                        self.generation_results.append({
                            "product": product["name"],
                            "success": False,
                            "error": f"HTTP {response.status}"
                        })
                
                # Pause entre les g√©n√©rations
                await asyncio.sleep(1)
                        
            except Exception as e:
                print(f"   ‚ùå Exception: {str(e)}")
                self.generation_results.append({
                    "product": product["name"],
                    "success": False,
                    "error": str(e)
                })
        
        # Analyse des r√©sultats
        print(f"\nüìä R√âSULTATS G√âN√âRATION MULTIPLE:")
        print(f"   ‚úÖ G√©n√©rations r√©ussies: {successful_generations}/10")
        print(f"   ‚ö° Fallbacks d√©clench√©s: {fallback_triggered_count}")
        print(f"   üìà Taux de succ√®s: {(successful_generations/10)*100:.1f}%")
        print(f"   üéØ Taux de fallback: {(fallback_triggered_count/max(successful_generations,1))*100:.1f}%")
        
        # Crit√®res de succ√®s
        success_criteria = {
            "at_least_8_successful": successful_generations >= 8,
            "at_least_1_fallback": fallback_triggered_count >= 1,
            "no_critical_errors": successful_generations > 0
        }
        
        print(f"\nüìã CRIT√àRES DE SUCC√àS MULTIPLE:")
        for criterion, met in success_criteria.items():
            status_icon = "‚úÖ" if met else "‚ùå"
            print(f"   {status_icon} {criterion}")
        
        overall_success = all(success_criteria.values())
        
        self.test_results.append({
            "test": "multiple_generations_qa",
            "success": overall_success,
            "successful_generations": successful_generations,
            "fallback_triggered_count": fallback_triggered_count,
            "success_rate": (successful_generations/10)*100,
            "fallback_rate": (fallback_triggered_count/max(successful_generations,1))*100,
            "criteria": success_criteria
        })
        
        return overall_success
    
    async def test_qa_statistics_endpoint(self):
        """
        TEST 3: ENDPOINT QA STATISTICS
        Tester GET /api/qa/statistics
        """
        print("\nüß™ TEST 3: ENDPOINT QA STATISTICS")
        print("=" * 60)
        
        if not self.test_user:
            print("‚ùå Utilisateur QA non disponible")
            return False
        
        try:
            # Test de l'endpoint QA statistics
            async with self.session.get(
                f"{BACKEND_URL}/qa/statistics",
                headers=self.get_auth_headers(self.test_user["token"])
            ) as response:
                
                if response.status == 200:
                    stats = await response.json()
                    
                    print(f"‚úÖ ENDPOINT QA STATISTICS ACCESSIBLE")
                    
                    # V√©rifier la structure des statistiques
                    expected_fields = [
                        "total_qa_tests", "fallback_simulations", "success_rate",
                        "average_generation_time", "recent_tests"
                    ]
                    
                    stats_validation = {}
                    for field in expected_fields:
                        present = field in stats
                        stats_validation[field] = present
                        status_icon = "‚úÖ" if present else "‚ùå"
                        print(f"   {status_icon} {field}: {stats.get(field, 'MANQUANT')}")
                    
                    # Afficher les statistiques si disponibles
                    if "recent_tests" in stats and isinstance(stats["recent_tests"], list):
                        print(f"\nüìã TESTS R√âCENTS QA ({len(stats['recent_tests'])}):")
                        for i, test in enumerate(stats["recent_tests"][:5], 1):
                            print(f"   {i}. {test.get('product_name', 'N/A')} - {test.get('status', 'N/A')}")
                    
                    success = sum(stats_validation.values()) >= len(expected_fields) // 2
                    
                    self.test_results.append({
                        "test": "qa_statistics_endpoint",
                        "success": success,
                        "stats_received": stats,
                        "fields_validation": stats_validation,
                        "fields_present": sum(stats_validation.values()),
                        "total_expected_fields": len(expected_fields)
                    })
                    
                    return success
                    
                elif response.status == 404:
                    print(f"‚ö†Ô∏è ENDPOINT QA STATISTICS NON IMPL√âMENT√â (404)")
                    self.test_results.append({
                        "test": "qa_statistics_endpoint",
                        "success": False,
                        "error": "Endpoint not implemented (404)"
                    })
                    return False
                    
                else:
                    error_text = await response.text()
                    print(f"‚ùå ERREUR ENDPOINT QA: {response.status} - {error_text}")
                    self.test_results.append({
                        "test": "qa_statistics_endpoint",
                        "success": False,
                        "error": f"HTTP {response.status}: {error_text[:200]}"
                    })
                    return False
                    
        except Exception as e:
            print(f"‚ùå EXCEPTION ENDPOINT QA: {str(e)}")
            self.test_results.append({
                "test": "qa_statistics_endpoint",
                "success": False,
                "error": str(e)
            })
            return False
    
    async def test_complete_macbook_generation(self):
        """
        TEST 4: TEST COMPLET G√âN√âRATION MACBOOK PRO M3 2024
        Test complet avec tous les crit√®res de qualit√©
        """
        print("\nüß™ TEST 4: G√âN√âRATION COMPL√àTE MACBOOK PRO M3 2024")
        print("=" * 60)
        
        if not self.test_user:
            print("‚ùå Utilisateur QA non disponible")
            return False
        
        # Test du produit sp√©cifique mentionn√© dans la review
        test_product = {
            "product_name": "MacBook Pro M3 2024",
            "product_description": "Ordinateur portable Apple avec puce M3, √©cran Liquid Retina XDR 14 pouces, 16GB RAM, 512GB SSD, pour professionnels cr√©atifs",
            "generate_image": True,
            "number_of_images": 2,
            "language": "fr",
            "category": "√©lectronique",
            "use_case": "travail professionnel cr√©atif",
            "image_style": "studio",
            "qa_test_mode": True
        }
        
        print(f"üî• Test complet: {test_product['product_name']}")
        
        try:
            start_time = time.time()
            
            async with self.session.post(
                f"{BACKEND_URL}/generate-sheet",
                json=test_product,
                headers=self.get_auth_headers(self.test_user["token"])
            ) as response:
                
                generation_time = time.time() - start_time
                status = response.status
                
                if status == 200:
                    result = await response.json()
                    
                    print(f"‚úÖ G√âN√âRATION MACBOOK R√âUSSIE en {generation_time:.2f}s")
                    
                    # Validation compl√®te de tous les champs des 6 phases
                    complete_validation = {
                        # Phase 1 - Services modulaires
                        "services_title": len(result.get('generated_title', '')) >= 20,
                        "services_description": len(result.get('marketing_description', '')) >= 200,
                        "services_features": len(result.get('key_features', [])) >= 5,
                        "services_seo": len(result.get('seo_tags', [])) >= 5,
                        "services_images": len(result.get('generated_images', [])) >= 1,
                        
                        # Phase 2 - Logging structur√©
                        "logging_time": result.get('generation_time') is not None,
                        "logging_id": result.get('generation_id') is not None,
                        
                        # Phase 3 - Validation entr√©es
                        "validation_structure": all(field in result for field in ['generated_title', 'marketing_description']),
                        
                        # Phase 4 - Champs fallback
                        "fallback_model": result.get('model_used') is not None,
                        "fallback_method": result.get('generation_method') is not None,
                        "fallback_level": result.get('fallback_level') is not None,
                        
                        # Phase 5 - Enrichissement SEO
                        "seo_source": result.get('seo_tags_source') is not None,
                        
                        # Phase 6 - Mode QA
                        "qa_mode": result.get('qa_test_mode') is not None,
                        "qa_simulation": result.get('qa_simulation_triggered') is not None
                    }
                    
                    # Crit√®res de performance
                    performance_criteria = {
                        "generation_under_60s": generation_time < 60,
                        "quality_title": 30 <= len(result.get('generated_title', '')) <= 80,
                        "quality_description": len(result.get('marketing_description', '')) >= 300,
                        "quality_features": len(result.get('key_features', [])) >= 5,
                        "quality_seo": len(result.get('seo_tags', [])) >= 5
                    }
                    
                    print(f"\nüìã VALIDATION COMPL√àTE DES 6 PHASES:")
                    phases_passed = 0
                    for criterion, passed in complete_validation.items():
                        status_icon = "‚úÖ" if passed else "‚ùå"
                        print(f"   {status_icon} {criterion}")
                        if passed:
                            phases_passed += 1
                    
                    print(f"\nüéØ CRIT√àRES DE PERFORMANCE:")
                    performance_passed = 0
                    for criterion, passed in performance_criteria.items():
                        status_icon = "‚úÖ" if passed else "‚ùå"
                        print(f"   {status_icon} {criterion}")
                        if passed:
                            performance_passed += 1
                    
                    # Affichage des d√©tails
                    print(f"\nüìä D√âTAILS G√âN√âRATION:")
                    print(f"   üìù Titre: {result.get('generated_title', 'N/A')[:60]}...")
                    print(f"   üìÑ Description: {len(result.get('marketing_description', ''))} caract√®res")
                    print(f"   üîß Features: {len(result.get('key_features', []))} √©l√©ments")
                    print(f"   üè∑Ô∏è SEO Tags: {len(result.get('seo_tags', []))} tags")
                    print(f"   üñºÔ∏è Images: {len(result.get('generated_images', []))} g√©n√©r√©es")
                    print(f"   ‚è±Ô∏è Temps: {generation_time:.2f}s")
                    print(f"   ü§ñ Mod√®le: {result.get('model_used', 'N/A')}")
                    print(f"   üîß M√©thode: {result.get('generation_method', 'N/A')}")
                    print(f"   üìä Fallback: {result.get('fallback_level', 'N/A')}")
                    print(f"   üè∑Ô∏è SEO Source: {result.get('seo_tags_source', 'N/A')}")
                    print(f"   üß™ QA Mode: {result.get('qa_test_mode', 'N/A')}")
                    print(f"   ‚ö° QA Simulation: {result.get('qa_simulation_triggered', 'N/A')}")
                    
                    # √âvaluation globale
                    total_criteria = len(complete_validation) + len(performance_criteria)
                    passed_criteria = phases_passed + performance_passed
                    success_rate = (passed_criteria / total_criteria) * 100
                    
                    overall_success = success_rate >= 80  # 80% des crit√®res doivent passer
                    
                    print(f"\nüéØ √âVALUATION GLOBALE:")
                    print(f"   üìä Crit√®res r√©ussis: {passed_criteria}/{total_criteria}")
                    print(f"   üìà Taux de r√©ussite: {success_rate:.1f}%")
                    print(f"   üéØ Statut: {'‚úÖ SUCC√àS' if overall_success else '‚ùå √âCHEC'}")
                    
                    self.test_results.append({
                        "test": "complete_macbook_generation",
                        "success": overall_success,
                        "generation_time": generation_time,
                        "phases_validation": complete_validation,
                        "performance_criteria": performance_criteria,
                        "phases_passed": phases_passed,
                        "performance_passed": performance_passed,
                        "total_criteria": total_criteria,
                        "success_rate": success_rate,
                        "result_details": {
                            "title_length": len(result.get('generated_title', '')),
                            "description_length": len(result.get('marketing_description', '')),
                            "features_count": len(result.get('key_features', [])),
                            "seo_tags_count": len(result.get('seo_tags', [])),
                            "images_count": len(result.get('generated_images', [])),
                            "model_used": result.get('model_used'),
                            "generation_method": result.get('generation_method'),
                            "fallback_level": result.get('fallback_level'),
                            "seo_tags_source": result.get('seo_tags_source'),
                            "qa_test_mode": result.get('qa_test_mode'),
                            "qa_simulation_triggered": result.get('qa_simulation_triggered')
                        }
                    })
                    
                    return overall_success
                else:
                    error_text = await response.text()
                    print(f"‚ùå ERREUR G√âN√âRATION MACBOOK: {status} - {error_text}")
                    self.test_results.append({
                        "test": "complete_macbook_generation",
                        "success": False,
                        "error": f"HTTP {status}: {error_text[:200]}"
                    })
                    return False
                    
        except Exception as e:
            print(f"‚ùå EXCEPTION G√âN√âRATION MACBOOK: {str(e)}")
            self.test_results.append({
                "test": "complete_macbook_generation",
                "success": False,
                "error": str(e)
            })
            return False
    
    async def run_comprehensive_qa_tests(self):
        """Run all comprehensive QA tests for the 6 phases"""
        print("üöÄ ECOMSIMPLY - TEST COMPLET SYST√àME 6 PHASES AVEC MODE QA")
        print("=" * 80)
        print("Objectif: Validation globale de toutes les phases avec mode QA activ√©")
        print("=" * 80)
        
        # Setup
        if not await self.setup_session():
            print("‚ùå Failed to setup test session")
            return False
        
        try:
            # Run all comprehensive tests
            print("\nüéØ D√âMARRAGE DES TESTS COMPLETS QA...")
            
            test1_result = await self.test_qa_mode_activation()
            await asyncio.sleep(2)
            
            test2_result = await self.test_multiple_generations_qa()
            await asyncio.sleep(2)
            
            test3_result = await self.test_qa_statistics_endpoint()
            await asyncio.sleep(2)
            
            test4_result = await self.test_complete_macbook_generation()
            
            # Final Summary
            print("\n" + "=" * 80)
            print("üèÅ R√âSUM√â FINAL - SYST√àME COMPLET 6 PHASES")
            print("=" * 80)
            
            total_tests = len(self.test_results)
            passed_tests = sum(1 for result in self.test_results if result.get('success', False))
            
            print(f"üìä Total Tests: {total_tests}")
            print(f"‚úÖ R√©ussis: {passed_tests}")
            print(f"‚ùå √âchou√©s: {total_tests - passed_tests}")
            print(f"üìà Taux de R√©ussite Global: {(passed_tests/total_tests*100):.1f}%")
            
            print(f"\nüéØ STATUT DES TESTS CRITIQUES:")
            print(f"   1. Mode QA Activ√©: {'‚úÖ R√âUSSI' if test1_result else '‚ùå √âCHOU√â'}")
            print(f"   2. G√©n√©rations Multiples QA: {'‚úÖ R√âUSSI' if test2_result else '‚ùå √âCHOU√â'}")
            print(f"   3. Endpoint QA Statistics: {'‚úÖ R√âUSSI' if test3_result else '‚ùå √âCHOU√â'}")
            print(f"   4. G√©n√©ration Compl√®te MacBook: {'‚úÖ R√âUSSI' if test4_result else '‚ùå √âCHOU√â'}")
            
            # Validation des 6 phases
            print(f"\nüìã VALIDATION DES 6 PHASES:")
            phases_status = {
                "Phase 1 - Services modulaires": test1_result and test4_result,
                "Phase 2 - Logging structur√©": test1_result and test4_result,
                "Phase 3 - Validation avanc√©e": test4_result,
                "Phase 4 - Champs fallback": test1_result and test4_result,
                "Phase 5 - Enrichissement SEO": test1_result and test4_result,
                "Phase 6 - Mode QA": test1_result and test2_result
            }
            
            for phase, working in phases_status.items():
                status_icon = "‚úÖ" if working else "‚ùå"
                print(f"   {status_icon} {phase}")
            
            # Crit√®res de succ√®s globaux
            success_criteria = {
                "qa_mode_functional": test1_result,
                "multiple_generations_working": test2_result,
                "fallback_system_active": any(r.get('fallback_triggered_count', 0) > 0 for r in self.test_results),
                "performance_acceptable": test4_result,
                "all_phases_detected": sum(phases_status.values()) >= 4  # Au moins 4/6 phases
            }
            
            print(f"\nüìã CRIT√àRES DE SUCC√àS GLOBAUX:")
            for criterion, met in success_criteria.items():
                status_icon = "‚úÖ" if met else "‚ùå"
                print(f"   {status_icon} {criterion}")
            
            # √âvaluation finale
            critical_success = test1_result and test4_result  # Mode QA + g√©n√©ration compl√®te
            overall_success = sum(success_criteria.values()) >= 4  # Au moins 4/5 crit√®res
            
            if overall_success:
                print(f"\nüéâ SUCC√àS COMPLET: Le syst√®me 6 phases avec mode QA fonctionne excellemment!")
                print("   ‚úÖ Mode QA avec simulation d'erreurs fonctionnel")
                print("   ‚úÖ Tous les champs des 6 phases pr√©sents dans l'API")
                print("   ‚úÖ Logging complet et structur√©")
                print("   ‚úÖ G√©n√©ration de contenu de qualit√© maintenue")
                print("   ‚úÖ Syst√®me robuste avec fallbacks automatiques")
                print("   ‚úÖ Performance acceptable (< 60s par g√©n√©ration)")
            elif critical_success:
                print(f"\n‚ö° SUCC√àS PARTIEL: Les fonctionnalit√©s critiques marchent!")
                print("   ‚úÖ Mode QA op√©rationnel")
                print("   ‚úÖ G√©n√©ration compl√®te fonctionnelle")
                if not test2_result:
                    print("   ‚ö†Ô∏è G√©n√©rations multiples n√©cessitent des ajustements")
                if not test3_result:
                    print("   ‚ö†Ô∏è Endpoint QA statistics √† impl√©menter")
            else:
                print(f"\n‚ùå √âCHEC CRITIQUE: Le syst√®me 6 phases pr√©sente des probl√®mes majeurs")
                if not test1_result:
                    print("   ‚ùå Mode QA non fonctionnel")
                if not test4_result:
                    print("   ‚ùå G√©n√©ration compl√®te d√©faillante")
                print("   üîß Correction imm√©diate requise")
            
            # R√©sum√© des phases pour le main agent
            phases_working = sum(phases_status.values())
            print(f"\nüìä R√âSUM√â FINAL DES 6 PHASES:")
            print(f"   üéØ Phases fonctionnelles: {phases_working}/6")
            print(f"   üìà Taux de r√©ussite phases: {(phases_working/6)*100:.1f}%")
            print(f"   üöÄ Syst√®me production-ready: {'‚úÖ OUI' if overall_success else '‚ùå NON'}")
            
            return critical_success
            
        finally:
            await self.cleanup()

async def main():
    """Main test execution"""
    tester = ComprehensivePhasesQATester()
    success = await tester.run_comprehensive_qa_tests()
    
    # Exit with appropriate code
    exit(0 if success else 1)

if __name__ == "__main__":
    asyncio.run(main())