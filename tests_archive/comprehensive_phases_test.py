#!/usr/bin/env python3
"""
ECOMSIMPLY COMPREHENSIVE PHASES TESTING - SYSTÃˆME COMPLET 6 PHASES
Test global de toutes les phases d'amÃ©lioration du systÃ¨me de gÃ©nÃ©ration de fiches produits avec mode QA.

PHASES Ã€ TESTER:
- Phase 1: Services modulaires fonctionnels
- Phase 2: Logging structurÃ© actif
- Phase 3: Validation avancÃ©e des entrÃ©es
- Phase 4: Champs fallback (model_used, generation_method, fallback_level)
- Phase 5: Enrichissement SEO (seo_tags_source)
- Phase 6: Mode QA (qa_test_mode, qa_simulation_triggered)

TESTS SPÃ‰CIFIQUES:
1. TEST MODE QA ACTIVÃ‰ avec TEST_MODE=True
2. GÃ©nÃ©ration de 10 fiches produits diffÃ©rentes
3. VÃ©rification qu'au moins 1 gÃ©nÃ©ration dÃ©clenche un fallback simulÃ©
4. Test endpoint QA statistics
5. Test complet gÃ©nÃ©ration MacBook Pro M3 2024
"""

import asyncio
import aiohttp
import json
import time
import os
import random
from typing import Dict, List, Any

# Backend URL from environment
BACKEND_URL = "https://ecomsimply.com/api"

class ComprehensivePhasesQATester:
    def __init__(self):
        self.session = None
        self.test_results = []
        self.test_user = None
        self.qa_mode_enabled = False
        self.generation_results = []
        
    async def setup_session(self):
        """Setup HTTP session"""
        self.session = aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=120)
        )
        print("âœ… Session HTTP initialisÃ©e pour tests QA")
        return True
    
    async def cleanup(self):
        """Cleanup HTTP session"""
        if self.session:
            await self.session.close()
    
    def get_auth_headers(self, token: str):
        """Get authorization headers"""
        return {"Authorization": f"Bearer {token}"}
    
    async def create_test_user(self) -> Dict:
        """Create a test user for QA testing"""
        
        user_data = {
            "email": f"qa_test_{int(time.time())}@ecomsimply.test",
            "name": "QA Test User",
            "password": "QATestPassword123!"
        }
        
        print(f"ðŸ‘¤ CrÃ©ation utilisateur QA test...")
        
        try:
            # Register user
            async with self.session.post(f"{BACKEND_URL}/auth/register", json=user_data) as response:
                if response.status == 200:
                    register_result = await response.json()
                    print(f"âœ… Utilisateur QA crÃ©Ã©: {user_data['email']}")
                    
                    # Login to get token
                    login_data = {
                        "email": user_data["email"],
                        "password": user_data["password"]
                    }
                    
                    async with self.session.post(f"{BACKEND_URL}/auth/login", json=login_data) as login_response:
                        if login_response.status == 200:
                            login_result = await login_response.json()
                            token = login_result.get("token")
                            
                            user_info = {
                                "email": user_data["email"],
                                "token": token,
                                "plan": "gratuit"
                            }
                            
                            self.test_user = user_info
                            print(f"âœ… Utilisateur QA prÃªt avec token")
                            return user_info
                        else:
                            error_text = await login_response.text()
                            print(f"âŒ Ã‰chec login QA: {login_response.status} - {error_text}")
                            return None
                else:
                    error_text = await response.text()
                    print(f"âŒ Ã‰chec crÃ©ation utilisateur QA: {response.status} - {error_text}")
                    return None
                    
        except Exception as e:
            print(f"âŒ Exception crÃ©ation utilisateur QA: {str(e)}")
            return None
    
    async def test_qa_mode_activation(self):
        """
        TEST 1: MODE QA ACTIVÃ‰
        VÃ©rifier que le mode QA peut Ãªtre activÃ© et fonctionne
        """
        print("\nðŸ§ª TEST 1: MODE QA ACTIVÃ‰")
        print("=" * 60)
        
        if not self.test_user:
            user_info = await self.create_test_user()
            if not user_info:
                print("âŒ Impossible de crÃ©er l'utilisateur QA")
                return False
        
        # Test avec mode QA activÃ© via paramÃ¨tre ou variable d'environnement
        test_product = {
            "product_name": "iPhone 15 Pro QA Test",
            "product_description": "Test du mode QA avec iPhone 15 Pro pour vÃ©rifier les fallbacks",
            "generate_image": True,
            "number_of_images": 1,
            "language": "fr",
            "category": "Ã©lectronique",
            "qa_test_mode": True  # Activation explicite du mode QA
        }
        
        print(f"ðŸ”¥ Test mode QA avec: {test_product['product_name']}")
        
        try:
            start_time = time.time()
            
            async with self.session.post(
                f"{BACKEND_URL}/generate-sheet",
                json=test_product,
                headers=self.get_auth_headers(self.test_user["token"])
            ) as response:
                
                generation_time = time.time() - start_time
                status = response.status
                
                if status == 200:
                    result = await response.json()
                    
                    # VÃ©rification des champs QA spÃ©cifiques
                    qa_fields = {
                        "qa_test_mode": result.get("qa_test_mode"),
                        "qa_simulation_triggered": result.get("qa_simulation_triggered"),
                        "model_used": result.get("model_used"),
                        "generation_method": result.get("generation_method"),
                        "fallback_level": result.get("fallback_level"),
                        "seo_tags_source": result.get("seo_tags_source")
                    }
                    
                    print(f"âœ… GÃ‰NÃ‰RATION QA RÃ‰USSIE en {generation_time:.2f}s")
                    print(f"   ðŸ¤– Mode QA: {qa_fields['qa_test_mode']}")
                    print(f"   âš¡ Simulation dÃ©clenchÃ©e: {qa_fields['qa_simulation_triggered']}")
                    print(f"   ðŸ§  ModÃ¨le utilisÃ©: {qa_fields['model_used']}")
                    print(f"   ðŸ”§ MÃ©thode gÃ©nÃ©ration: {qa_fields['generation_method']}")
                    print(f"   ðŸ“Š Niveau fallback: {qa_fields['fallback_level']}")
                    print(f"   ðŸ·ï¸ Source SEO tags: {qa_fields['seo_tags_source']}")
                    
                    # Validation des phases
                    phase_validation = {
                        "Phase 1 - Services modulaires": len(result.get('generated_images', [])) > 0 and len(result.get('key_features', [])) >= 5,
                        "Phase 2 - Logging structurÃ©": result.get('generation_time') is not None,
                        "Phase 3 - Validation entrÃ©es": len(result.get('generated_title', '')) > 0,
                        "Phase 4 - Champs fallback": qa_fields['model_used'] is not None,
                        "Phase 5 - Enrichissement SEO": qa_fields['seo_tags_source'] is not None,
                        "Phase 6 - Mode QA": qa_fields['qa_test_mode'] is not None
                    }
                    
                    print(f"\nðŸ“‹ VALIDATION DES 6 PHASES:")
                    for phase, validated in phase_validation.items():
                        status_icon = "âœ…" if validated else "âŒ"
                        print(f"   {status_icon} {phase}")
                    
                    self.test_results.append({
                        "test": "qa_mode_activation",
                        "success": True,
                        "generation_time": generation_time,
                        "qa_fields": qa_fields,
                        "phase_validation": phase_validation,
                        "phases_passed": sum(phase_validation.values()),
                        "total_phases": len(phase_validation)
                    })
                    
                    self.qa_mode_enabled = qa_fields.get('qa_test_mode', False)
                    return True
                else:
                    error_text = await response.text()
                    print(f"âŒ ERREUR MODE QA: {status} - {error_text}")
                    self.test_results.append({
                        "test": "qa_mode_activation",
                        "success": False,
                        "error": f"HTTP {status}: {error_text[:200]}"
                    })
                    return False
                    
        except Exception as e:
            print(f"âŒ EXCEPTION MODE QA: {str(e)}")
            self.test_results.append({
                "test": "qa_mode_activation",
                "success": False,
                "error": str(e)
            })
            return False
    
    async def test_multiple_generations_qa(self):
        """
        TEST 2: GÃ‰NÃ‰RATION DE 10 FICHES PRODUITS DIFFÃ‰RENTES
        VÃ©rifier qu'au moins 1 gÃ©nÃ©ration dÃ©clenche un fallback simulÃ©
        """
        print("\nðŸ§ª TEST 2: GÃ‰NÃ‰RATION MULTIPLE AVEC QA")
        print("=" * 60)
        
        if not self.test_user:
            print("âŒ Utilisateur QA non disponible")
            return False
        
        # 10 produits diffÃ©rents pour tester la variÃ©tÃ©
        test_products = [
            {"name": "MacBook Pro M3 2024", "desc": "Ordinateur portable Apple avec puce M3 pour professionnels", "cat": "Ã©lectronique"},
            {"name": "iPhone 15 Pro Max", "desc": "Smartphone Apple haut de gamme avec appareil photo 48MP", "cat": "Ã©lectronique"},
            {"name": "Nike Air Max 270", "desc": "Chaussures de sport Nike avec technologie Air Max", "cat": "sport"},
            {"name": "Samsung Galaxy S24 Ultra", "desc": "Smartphone Samsung avec S Pen et Ã©cran 6.8 pouces", "cat": "Ã©lectronique"},
            {"name": "Sony WH-1000XM5", "desc": "Casque audio sans fil avec rÃ©duction de bruit active", "cat": "Ã©lectronique"},
            {"name": "Adidas Ultraboost 22", "desc": "Chaussures de running Adidas avec technologie Boost", "cat": "sport"},
            {"name": "iPad Pro 12.9 M2", "desc": "Tablette Apple avec Ã©cran Liquid Retina XDR", "cat": "Ã©lectronique"},
            {"name": "Nintendo Switch OLED", "desc": "Console de jeu portable Nintendo avec Ã©cran OLED", "cat": "Ã©lectronique"},
            {"name": "AirPods Pro 2", "desc": "Ã‰couteurs sans fil Apple avec rÃ©duction de bruit", "cat": "Ã©lectronique"},
            {"name": "Tesla Model 3", "desc": "Voiture Ã©lectrique Tesla avec autopilot", "cat": "auto"}
        ]
        
        fallback_triggered_count = 0
        successful_generations = 0
        
        print(f"ðŸ”¥ Test de {len(test_products)} gÃ©nÃ©rations avec mode QA")
        
        for i, product in enumerate(test_products, 1):
            print(f"\nðŸ“± GÃ©nÃ©ration {i}/10: {product['name']}")
            
            test_request = {
                "product_name": product["name"],
                "product_description": product["desc"],
                "generate_image": True,
                "number_of_images": 1,
                "language": "fr",
                "category": product["cat"],
                "qa_test_mode": True
            }
            
            try:
                start_time = time.time()
                
                async with self.session.post(
                    f"{BACKEND_URL}/generate-sheet",
                    json=test_request,
                    headers=self.get_auth_headers(self.test_user["token"])
                ) as response:
                    
                    generation_time = time.time() - start_time
                    
                    if response.status == 200:
                        result = await response.json()
                        successful_generations += 1
                        
                        # VÃ©rifier si un fallback a Ã©tÃ© dÃ©clenchÃ©
                        qa_simulation = result.get("qa_simulation_triggered", False)
                        fallback_level = result.get("fallback_level", 0)
                        
                        if qa_simulation or (fallback_level and fallback_level > 1):
                            fallback_triggered_count += 1
                            print(f"   âš¡ FALLBACK DÃ‰TECTÃ‰! (Simulation: {qa_simulation}, Niveau: {fallback_level})")
                        else:
                            print(f"   âœ… GÃ©nÃ©ration normale (Temps: {generation_time:.1f}s)")
                        
                        # Stocker les rÃ©sultats pour analyse
                        self.generation_results.append({
                            "product": product["name"],
                            "success": True,
                            "generation_time": generation_time,
                            "qa_simulation_triggered": qa_simulation,
                            "fallback_level": fallback_level,
                            "model_used": result.get("model_used"),
                            "seo_tags_source": result.get("seo_tags_source")
                        })
                        
                    else:
                        error_text = await response.text()
                        print(f"   âŒ Erreur: {response.status} - {error_text[:100]}")
                        self.generation_results.append({
                            "product": product["name"],
                            "success": False,
                            "error": f"HTTP {response.status}"
                        })
                
                # Pause entre les gÃ©nÃ©rations
                await asyncio.sleep(1)
                        
            except Exception as e:
                print(f"   âŒ Exception: {str(e)}")
                self.generation_results.append({
                    "product": product["name"],
                    "success": False,
                    "error": str(e)
                })
        
        # Analyse des rÃ©sultats
        print(f"\nðŸ“Š RÃ‰SULTATS GÃ‰NÃ‰RATION MULTIPLE:")
        print(f"   âœ… GÃ©nÃ©rations rÃ©ussies: {successful_generations}/10")
        print(f"   âš¡ Fallbacks dÃ©clenchÃ©s: {fallback_triggered_count}")
        print(f"   ðŸ“ˆ Taux de succÃ¨s: {(successful_generations/10)*100:.1f}%")
        print(f"   ðŸŽ¯ Taux de fallback: {(fallback_triggered_count/max(successful_generations,1))*100:.1f}%")
        
        # CritÃ¨res de succÃ¨s
        success_criteria = {
            "at_least_8_successful": successful_generations >= 8,
            "at_least_1_fallback": fallback_triggered_count >= 1,
            "no_critical_errors": successful_generations > 0
        }
        
        print(f"\nðŸ“‹ CRITÃˆRES DE SUCCÃˆS MULTIPLE:")
        for criterion, met in success_criteria.items():
            status_icon = "âœ…" if met else "âŒ"
            print(f"   {status_icon} {criterion}")
        
        overall_success = all(success_criteria.values())
        
        self.test_results.append({
            "test": "multiple_generations_qa",
            "success": overall_success,
            "successful_generations": successful_generations,
            "fallback_triggered_count": fallback_triggered_count,
            "success_rate": (successful_generations/10)*100,
            "fallback_rate": (fallback_triggered_count/max(successful_generations,1))*100,
            "criteria": success_criteria
        })
        
        return overall_success
    
    async def test_qa_statistics_endpoint(self):
        """
        TEST 3: ENDPOINT QA STATISTICS
        Tester GET /api/qa/statistics
        """
        print("\nðŸ§ª TEST 3: ENDPOINT QA STATISTICS")
        print("=" * 60)
        
        if not self.test_user:
            print("âŒ Utilisateur QA non disponible")
            return False
        
        try:
            # Test de l'endpoint QA statistics
            async with self.session.get(
                f"{BACKEND_URL}/qa/statistics",
                headers=self.get_auth_headers(self.test_user["token"])
            ) as response:
                
                if response.status == 200:
                    stats = await response.json()
                    
                    print(f"âœ… ENDPOINT QA STATISTICS ACCESSIBLE")
                    
                    # VÃ©rifier la structure des statistiques
                    expected_fields = [
                        "total_qa_tests", "fallback_simulations", "success_rate",
                        "average_generation_time", "recent_tests"
                    ]
                    
                    stats_validation = {}
                    for field in expected_fields:
                        present = field in stats
                        stats_validation[field] = present
                        status_icon = "âœ…" if present else "âŒ"
                        print(f"   {status_icon} {field}: {stats.get(field, 'MANQUANT')}")
                    
                    # Afficher les statistiques si disponibles
                    if "recent_tests" in stats and isinstance(stats["recent_tests"], list):
                        print(f"\nðŸ“‹ TESTS RÃ‰CENTS QA ({len(stats['recent_tests'])}):")
                        for i, test in enumerate(stats["recent_tests"][:5], 1):
                            print(f"   {i}. {test.get('product_name', 'N/A')} - {test.get('status', 'N/A')}")
                    
                    success = sum(stats_validation.values()) >= len(expected_fields) // 2
                    
                    self.test_results.append({
                        "test": "qa_statistics_endpoint",
                        "success": success,
                        "stats_received": stats,
                        "fields_validation": stats_validation,
                        "fields_present": sum(stats_validation.values()),
                        "total_expected_fields": len(expected_fields)
                    })
                    
                    return success
                    
                elif response.status == 404:
                    print(f"âš ï¸ ENDPOINT QA STATISTICS NON IMPLÃ‰MENTÃ‰ (404)")
                    self.test_results.append({
                        "test": "qa_statistics_endpoint",
                        "success": False,
                        "error": "Endpoint not implemented (404)"
                    })
                    return False
                    
                else:
                    error_text = await response.text()
                    print(f"âŒ ERREUR ENDPOINT QA: {response.status} - {error_text}")
                    self.test_results.append({
                        "test": "qa_statistics_endpoint",
                        "success": False,
                        "error": f"HTTP {response.status}: {error_text[:200]}"
                    })
                    return False
                    
        except Exception as e:
            print(f"âŒ EXCEPTION ENDPOINT QA: {str(e)}")
            self.test_results.append({
                "test": "qa_statistics_endpoint",
                "success": False,
                "error": str(e)
            })
            return False
    
    async def test_complete_macbook_generation(self):
        """
        TEST 4: TEST COMPLET GÃ‰NÃ‰RATION MACBOOK PRO M3 2024
        Test complet avec tous les critÃ¨res de qualitÃ©
        """
        print("\nðŸ§ª TEST 4: GÃ‰NÃ‰RATION COMPLÃˆTE MACBOOK PRO M3 2024")
        print("=" * 60)
        
        if not self.test_user:
            print("âŒ Utilisateur QA non disponible")
            return False
        
        # Test du produit spÃ©cifique mentionnÃ© dans la review
        test_product = {
            "product_name": "MacBook Pro M3 2024",
            "product_description": "Ordinateur portable Apple avec puce M3, Ã©cran Liquid Retina XDR 14 pouces, 16GB RAM, 512GB SSD, pour professionnels crÃ©atifs",
            "generate_image": True,
            "number_of_images": 2,
            "language": "fr",
            "category": "Ã©lectronique",
            "use_case": "travail professionnel crÃ©atif",
            "image_style": "studio",
            "qa_test_mode": True
        }
        
        print(f"ðŸ”¥ Test complet: {test_product['product_name']}")
        
        try:
            start_time = time.time()
            
            async with self.session.post(
                f"{BACKEND_URL}/generate-sheet",
                json=test_product,
                headers=self.get_auth_headers(self.test_user["token"])
            ) as response:
                
                generation_time = time.time() - start_time
                status = response.status
                
                if status == 200:
                    result = await response.json()
                    
                    print(f"âœ… GÃ‰NÃ‰RATION MACBOOK RÃ‰USSIE en {generation_time:.2f}s")
                    
                    # Validation complÃ¨te de tous les champs des 6 phases
                    complete_validation = {
                        # Phase 1 - Services modulaires
                        "services_title": len(result.get('generated_title', '')) >= 20,
                        "services_description": len(result.get('marketing_description', '')) >= 200,
                        "services_features": len(result.get('key_features', [])) >= 5,
                        "services_seo": len(result.get('seo_tags', [])) >= 5,
                        "services_images": len(result.get('generated_images', [])) >= 1,
                        
                        # Phase 2 - Logging structurÃ©
                        "logging_time": result.get('generation_time') is not None,
                        "logging_id": result.get('generation_id') is not None,
                        
                        # Phase 3 - Validation entrÃ©es
                        "validation_structure": all(field in result for field in ['generated_title', 'marketing_description']),
                        
                        # Phase 4 - Champs fallback
                        "fallback_model": result.get('model_used') is not None,
                        "fallback_method": result.get('generation_method') is not None,
                        "fallback_level": result.get('fallback_level') is not None,
                        
                        # Phase 5 - Enrichissement SEO
                        "seo_source": result.get('seo_tags_source') is not None,
                        
                        # Phase 6 - Mode QA
                        "qa_mode": result.get('qa_test_mode') is not None,
                        "qa_simulation": result.get('qa_simulation_triggered') is not None
                    }
                    
                    # CritÃ¨res de performance
                    performance_criteria = {
                        "generation_under_60s": generation_time < 60,
                        "quality_title": 30 <= len(result.get('generated_title', '')) <= 80,
                        "quality_description": len(result.get('marketing_description', '')) >= 300,
                        "quality_features": len(result.get('key_features', [])) >= 5,
                        "quality_seo": len(result.get('seo_tags', [])) >= 5
                    }
                    
                    print(f"\nðŸ“‹ VALIDATION COMPLÃˆTE DES 6 PHASES:")
                    phases_passed = 0
                    for criterion, passed in complete_validation.items():
                        status_icon = "âœ…" if passed else "âŒ"
                        print(f"   {status_icon} {criterion}")
                        if passed:
                            phases_passed += 1
                    
                    print(f"\nðŸŽ¯ CRITÃˆRES DE PERFORMANCE:")
                    performance_passed = 0
                    for criterion, passed in performance_criteria.items():
                        status_icon = "âœ…" if passed else "âŒ"
                        print(f"   {status_icon} {criterion}")
                        if passed:
                            performance_passed += 1
                    
                    # Affichage des dÃ©tails
                    print(f"\nðŸ“Š DÃ‰TAILS GÃ‰NÃ‰RATION:")
                    print(f"   ðŸ“ Titre: {result.get('generated_title', 'N/A')[:60]}...")
                    print(f"   ðŸ“„ Description: {len(result.get('marketing_description', ''))} caractÃ¨res")
                    print(f"   ðŸ”§ Features: {len(result.get('key_features', []))} Ã©lÃ©ments")
                    print(f"   ðŸ·ï¸ SEO Tags: {len(result.get('seo_tags', []))} tags")
                    print(f"   ðŸ–¼ï¸ Images: {len(result.get('generated_images', []))} gÃ©nÃ©rÃ©es")
                    print(f"   â±ï¸ Temps: {generation_time:.2f}s")
                    print(f"   ðŸ¤– ModÃ¨le: {result.get('model_used', 'N/A')}")
                    print(f"   ðŸ”§ MÃ©thode: {result.get('generation_method', 'N/A')}")
                    print(f"   ðŸ“Š Fallback: {result.get('fallback_level', 'N/A')}")
                    print(f"   ðŸ·ï¸ SEO Source: {result.get('seo_tags_source', 'N/A')}")
                    print(f"   ðŸ§ª QA Mode: {result.get('qa_test_mode', 'N/A')}")
                    print(f"   âš¡ QA Simulation: {result.get('qa_simulation_triggered', 'N/A')}")
                    
                    # Ã‰valuation globale
                    total_criteria = len(complete_validation) + len(performance_criteria)
                    passed_criteria = phases_passed + performance_passed
                    success_rate = (passed_criteria / total_criteria) * 100
                    
                    overall_success = success_rate >= 80  # 80% des critÃ¨res doivent passer
                    
                    print(f"\nðŸŽ¯ Ã‰VALUATION GLOBALE:")
                    print(f"   ðŸ“Š CritÃ¨res rÃ©ussis: {passed_criteria}/{total_criteria}")
                    print(f"   ðŸ“ˆ Taux de rÃ©ussite: {success_rate:.1f}%")
                    print(f"   ðŸŽ¯ Statut: {'âœ… SUCCÃˆS' if overall_success else 'âŒ Ã‰CHEC'}")
                    
                    self.test_results.append({
                        "test": "complete_macbook_generation",
                        "success": overall_success,
                        "generation_time": generation_time,
                        "phases_validation": complete_validation,
                        "performance_criteria": performance_criteria,
                        "phases_passed": phases_passed,
                        "performance_passed": performance_passed,
                        "total_criteria": total_criteria,
                        "success_rate": success_rate,
                        "result_details": {
                            "title_length": len(result.get('generated_title', '')),
                            "description_length": len(result.get('marketing_description', '')),
                            "features_count": len(result.get('key_features', [])),
                            "seo_tags_count": len(result.get('seo_tags', [])),
                            "images_count": len(result.get('generated_images', [])),
                            "model_used": result.get('model_used'),
                            "generation_method": result.get('generation_method'),
                            "fallback_level": result.get('fallback_level'),
                            "seo_tags_source": result.get('seo_tags_source'),
                            "qa_test_mode": result.get('qa_test_mode'),
                            "qa_simulation_triggered": result.get('qa_simulation_triggered')
                        }
                    })
                    
                    return overall_success
                else:
                    error_text = await response.text()
                    print(f"âŒ ERREUR GÃ‰NÃ‰RATION MACBOOK: {status} - {error_text}")
                    self.test_results.append({
                        "test": "complete_macbook_generation",
                        "success": False,
                        "error": f"HTTP {status}: {error_text[:200]}"
                    })
                    return False
                    
        except Exception as e:
            print(f"âŒ EXCEPTION GÃ‰NÃ‰RATION MACBOOK: {str(e)}")
            self.test_results.append({
                "test": "complete_macbook_generation",
                "success": False,
                "error": str(e)
            })
            return False
    
    async def run_comprehensive_qa_tests(self):
        """Run all comprehensive QA tests for the 6 phases"""
        print("ðŸš€ ECOMSIMPLY - TEST COMPLET SYSTÃˆME 6 PHASES AVEC MODE QA")
        print("=" * 80)
        print("Objectif: Validation globale de toutes les phases avec mode QA activÃ©")
        print("=" * 80)
        
        # Setup
        if not await self.setup_session():
            print("âŒ Failed to setup test session")
            return False
        
        try:
            # Run all comprehensive tests
            print("\nðŸŽ¯ DÃ‰MARRAGE DES TESTS COMPLETS QA...")
            
            test1_result = await self.test_qa_mode_activation()
            await asyncio.sleep(2)
            
            test2_result = await self.test_multiple_generations_qa()
            await asyncio.sleep(2)
            
            test3_result = await self.test_qa_statistics_endpoint()
            await asyncio.sleep(2)
            
            test4_result = await self.test_complete_macbook_generation()
            
            # Final Summary
            print("\n" + "=" * 80)
            print("ðŸ RÃ‰SUMÃ‰ FINAL - SYSTÃˆME COMPLET 6 PHASES")
            print("=" * 80)
            
            total_tests = len(self.test_results)
            passed_tests = sum(1 for result in self.test_results if result.get('success', False))
            
            print(f"ðŸ“Š Total Tests: {total_tests}")
            print(f"âœ… RÃ©ussis: {passed_tests}")
            print(f"âŒ Ã‰chouÃ©s: {total_tests - passed_tests}")
            print(f"ðŸ“ˆ Taux de RÃ©ussite Global: {(passed_tests/total_tests*100):.1f}%")
            
            print(f"\nðŸŽ¯ STATUT DES TESTS CRITIQUES:")
            print(f"   1. Mode QA ActivÃ©: {'âœ… RÃ‰USSI' if test1_result else 'âŒ Ã‰CHOUÃ‰'}")
            print(f"   2. GÃ©nÃ©rations Multiples QA: {'âœ… RÃ‰USSI' if test2_result else 'âŒ Ã‰CHOUÃ‰'}")
            print(f"   3. Endpoint QA Statistics: {'âœ… RÃ‰USSI' if test3_result else 'âŒ Ã‰CHOUÃ‰'}")
            print(f"   4. GÃ©nÃ©ration ComplÃ¨te MacBook: {'âœ… RÃ‰USSI' if test4_result else 'âŒ Ã‰CHOUÃ‰'}")
            
            # Validation des 6 phases
            print(f"\nðŸ“‹ VALIDATION DES 6 PHASES:")
            phases_status = {
                "Phase 1 - Services modulaires": test1_result and test4_result,
                "Phase 2 - Logging structurÃ©": test1_result and test4_result,
                "Phase 3 - Validation avancÃ©e": test4_result,
                "Phase 4 - Champs fallback": test1_result and test4_result,
                "Phase 5 - Enrichissement SEO": test1_result and test4_result,
                "Phase 6 - Mode QA": test1_result and test2_result
            }
            
            for phase, working in phases_status.items():
                status_icon = "âœ…" if working else "âŒ"
                print(f"   {status_icon} {phase}")
            
            # CritÃ¨res de succÃ¨s globaux
            success_criteria = {
                "qa_mode_functional": test1_result,
                "multiple_generations_working": test2_result,
                "fallback_system_active": any(r.get('fallback_triggered_count', 0) > 0 for r in self.test_results),
                "performance_acceptable": test4_result,
                "all_phases_detected": sum(phases_status.values()) >= 4  # Au moins 4/6 phases
            }
            
            print(f"\nðŸ“‹ CRITÃˆRES DE SUCCÃˆS GLOBAUX:")
            for criterion, met in success_criteria.items():
                status_icon = "âœ…" if met else "âŒ"
                print(f"   {status_icon} {criterion}")
            
            # Ã‰valuation finale
            critical_success = test1_result and test4_result  # Mode QA + gÃ©nÃ©ration complÃ¨te
            overall_success = sum(success_criteria.values()) >= 4  # Au moins 4/5 critÃ¨res
            
            if overall_success:
                print(f"\nðŸŽ‰ SUCCÃˆS COMPLET: Le systÃ¨me 6 phases avec mode QA fonctionne excellemment!")
                print("   âœ… Mode QA avec simulation d'erreurs fonctionnel")
                print("   âœ… Tous les champs des 6 phases prÃ©sents dans l'API")
                print("   âœ… Logging complet et structurÃ©")
                print("   âœ… GÃ©nÃ©ration de contenu de qualitÃ© maintenue")
                print("   âœ… SystÃ¨me robuste avec fallbacks automatiques")
                print("   âœ… Performance acceptable (< 60s par gÃ©nÃ©ration)")
            elif critical_success:
                print(f"\nâš¡ SUCCÃˆS PARTIEL: Les fonctionnalitÃ©s critiques marchent!")
                print("   âœ… Mode QA opÃ©rationnel")
                print("   âœ… GÃ©nÃ©ration complÃ¨te fonctionnelle")
                if not test2_result:
                    print("   âš ï¸ GÃ©nÃ©rations multiples nÃ©cessitent des ajustements")
                if not test3_result:
                    print("   âš ï¸ Endpoint QA statistics Ã  implÃ©menter")
            else:
                print(f"\nâŒ Ã‰CHEC CRITIQUE: Le systÃ¨me 6 phases prÃ©sente des problÃ¨mes majeurs")
                if not test1_result:
                    print("   âŒ Mode QA non fonctionnel")
                if not test4_result:
                    print("   âŒ GÃ©nÃ©ration complÃ¨te dÃ©faillante")
                print("   ðŸ”§ Correction immÃ©diate requise")
            
            # RÃ©sumÃ© des phases pour le main agent
            phases_working = sum(phases_status.values())
            print(f"\nðŸ“Š RÃ‰SUMÃ‰ FINAL DES 6 PHASES:")
            print(f"   ðŸŽ¯ Phases fonctionnelles: {phases_working}/6")
            print(f"   ðŸ“ˆ Taux de rÃ©ussite phases: {(phases_working/6)*100:.1f}%")
            print(f"   ðŸš€ SystÃ¨me production-ready: {'âœ… OUI' if overall_success else 'âŒ NON'}")
            
            return critical_success
            
        finally:
            await self.cleanup()

async def main():
    """Main test execution"""
    tester = ComprehensivePhasesQATester()
    success = await tester.run_comprehensive_qa_tests()
    
    # Exit with appropriate code
    exit(0 if success else 1)

if __name__ == "__main__":
    asyncio.run(main())