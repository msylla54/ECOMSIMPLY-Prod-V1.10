#!/usr/bin/env python3
"""
ECOMSIMPLY Mock Publication System Testing
Test des 3 premi√®res √©tapes de la roadmap: publication mock int√©gr√©e
"""

import asyncio
import aiohttp
import json
import os
import sys
from datetime import datetime
from typing import Dict, List, Any, Optional

# Configuration des URLs
BACKEND_URL = "https://ecomsimply.com/api"

class MockPublicationTester:
    """Testeur pour le syst√®me de publication mock ECOMSIMPLY"""
    
    def __init__(self):
        self.session = None
        self.auth_token = None
        self.test_results = []
        self.test_user_email = f"test_mock_pub_{int(datetime.now().timestamp())}@ecomsimply.test"
        self.test_user_password = "TestMockPub2025!"
        
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    def log_test(self, test_name: str, success: bool, details: str, data: Dict = None):
        """Log un r√©sultat de test"""
        result = {
            "test": test_name,
            "success": success,
            "details": details,
            "timestamp": datetime.now().isoformat(),
            "data": data or {}
        }
        self.test_results.append(result)
        
        status = "‚úÖ PASS" if success else "‚ùå FAIL"
        print(f"{status} {test_name}: {details}")
        
        if data and not success:
            print(f"   üìã Data: {json.dumps(data, indent=2)}")
    
    async def setup_test_user(self) -> bool:
        """Cr√©e un utilisateur de test"""
        try:
            # Cr√©er utilisateur
            register_data = {
                "email": self.test_user_email,
                "name": "Test Mock Publication User",
                "password": self.test_user_password
            }
            
            async with self.session.post(
                f"{BACKEND_URL}/auth/register",
                json=register_data
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    self.auth_token = result.get("token") or result.get("access_token")
                    
                    # Si pas de token dans register, essayer login
                    if not self.auth_token:
                        login_success = await self.login_user()
                        if login_success:
                            self.log_test(
                                "User Setup",
                                True,
                                f"Utilisateur test cr√©√© et connect√©: {self.test_user_email}",
                                {"user_email": self.test_user_email}
                            )
                            return True
                        else:
                            return False
                    else:
                        self.log_test(
                            "User Setup",
                            True,
                            f"Utilisateur test cr√©√©: {self.test_user_email}",
                            {"user_email": self.test_user_email}
                        )
                        return True
                else:
                    error_text = await response.text()
                    self.log_test(
                        "User Setup",
                        False,
                        f"√âchec cr√©ation utilisateur: {response.status}",
                        {"error": error_text}
                    )
                    return False
                    
        except Exception as e:
            self.log_test(
                "User Setup",
                False,
                f"Erreur setup utilisateur: {str(e)}"
            )
            return False
    
    async def login_user(self) -> bool:
        """Connecte l'utilisateur de test"""
        try:
            login_data = {
                "email": self.test_user_email,
                "password": self.test_user_password
            }
            
            async with self.session.post(
                f"{BACKEND_URL}/auth/login",
                json=login_data
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    self.auth_token = result.get("token") or result.get("access_token")
                    return bool(self.auth_token)
                else:
                    return False
                    
        except Exception as e:
            return False
    
    async def test_generate_sheet_with_auto_publish(self) -> bool:
        """Test 1: G√©n√©ration avec publication automatique"""
        try:
            # Donn√©es de test recommand√©es
            request_data = {
                "product_name": "iPhone 15 Pro Test",
                "product_description": "Smartphone premium avec processeur A17 Pro et appareil photo 48MP. Design en titane avec √©cran Super Retina XDR de 6.1 pouces.",
                "category": "Electronics",
                "generate_image": False,  # Plus rapide pour les tests
                "number_of_images": 0,
                "language": "fr"
            }
            
            headers = {"Authorization": f"Bearer {self.auth_token}"}
            
            # V√©rifier que PUBLISH_AUTO est activ√© (via variables d'environnement)
            print("üîß Test avec PUBLISH_AUTO=true (configuration par d√©faut)")
            
            async with self.session.post(
                f"{BACKEND_URL}/generate-sheet",
                json=request_data,
                headers=headers
            ) as response:
                
                if response.status == 200:
                    result = await response.json()
                    
                    # V√©rifications sp√©cifiques
                    checks = []
                    
                    # 1. V√©rifier que la g√©n√©ration a r√©ussi
                    has_title = bool(result.get("generated_title"))
                    has_description = bool(result.get("marketing_description"))
                    has_features = len(result.get("key_features", [])) > 0
                    has_seo_tags = len(result.get("seo_tags", [])) > 0
                    
                    checks.append(("Titre g√©n√©r√©", has_title))
                    checks.append(("Description g√©n√©r√©e", has_description))
                    checks.append(("Features g√©n√©r√©es", has_features))
                    checks.append(("Tags SEO g√©n√©r√©s", has_seo_tags))
                    
                    # 2. V√©rifier la publication automatique
                    auto_publish_enabled = result.get("auto_publish_enabled", False)
                    publication_results = result.get("publication_results", [])
                    
                    checks.append(("Auto-publish activ√©", auto_publish_enabled))
                    checks.append(("R√©sultats publication pr√©sents", len(publication_results) > 0))
                    
                    # 3. Analyser les r√©sultats de publication
                    successful_pubs = [p for p in publication_results if p.get("success")]
                    failed_pubs = [p for p in publication_results if not p.get("success")]
                    
                    platforms_tested = [p.get("platform") for p in publication_results]
                    expected_platforms = ["shopify", "woocommerce", "prestashop"]
                    
                    checks.append(("Publications r√©ussies", len(successful_pubs) >= 2))
                    checks.append(("Plateformes test√©es", len(platforms_tested) >= 3))
                    checks.append(("Mode mock utilis√©", all(p.get("mode") == "mock" for p in publication_results)))
                    
                    # R√©sum√© des v√©rifications
                    passed_checks = sum(1 for _, passed in checks if passed)
                    total_checks = len(checks)
                    
                    success = passed_checks >= (total_checks * 0.8)  # 80% de r√©ussite minimum
                    
                    details = f"G√©n√©ration + Publication: {passed_checks}/{total_checks} v√©rifications pass√©es"
                    if successful_pubs:
                        details += f", {len(successful_pubs)} publications r√©ussies sur {expected_platforms}"
                    
                    self.log_test(
                        "Generate Sheet + Auto Publish",
                        success,
                        details,
                        {
                            "checks": dict(checks),
                            "publication_results": publication_results,
                            "successful_publications": len(successful_pubs),
                            "failed_publications": len(failed_pubs),
                            "platforms_tested": platforms_tested
                        }
                    )
                    
                    return success
                    
                else:
                    error_text = await response.text()
                    self.log_test(
                        "Generate Sheet + Auto Publish",
                        False,
                        f"Erreur HTTP {response.status}",
                        {"error": error_text}
                    )
                    return False
                    
        except Exception as e:
            self.log_test(
                "Generate Sheet + Auto Publish",
                False,
                f"Exception: {str(e)}"
            )
            return False
    
    async def test_publication_status_endpoint(self) -> bool:
        """Test 2: Endpoint /api/status/publication"""
        try:
            async with self.session.get(f"{BACKEND_URL}/status/publication") as response:
                
                if response.status == 200:
                    result = await response.json()
                    
                    # V√©rifications
                    checks = []
                    
                    success_field = result.get("success", False)
                    status_data = result.get("status", {})
                    
                    checks.append(("R√©ponse success", success_field))
                    checks.append(("Donn√©es status pr√©sentes", bool(status_data)))
                    
                    # V√©rifier les champs attendus
                    expected_fields = [
                        "mode", "mock_mode", "auto_publish", "platforms_available",
                        "platforms", "health_checks"
                    ]
                    
                    for field in expected_fields:
                        checks.append((f"Champ {field}", field in status_data))
                    
                    # V√©rifications sp√©cifiques mode mock
                    mock_mode = status_data.get("mock_mode", False)
                    auto_publish = status_data.get("auto_publish", False)
                    platforms_available = status_data.get("platforms_available", 0)
                    
                    checks.append(("Mode mock activ√©", mock_mode))
                    checks.append(("Auto-publish configur√©", auto_publish))
                    checks.append(("Plateformes disponibles", platforms_available >= 3))
                    
                    # V√©rifier les health checks
                    health_checks = status_data.get("health_checks", {})
                    expected_platforms = ["shopify", "woocommerce", "prestashop"]
                    
                    for platform in expected_platforms:
                        platform_health = health_checks.get(platform, {})
                        checks.append((f"Health check {platform}", bool(platform_health)))
                    
                    # V√©rifier les statistiques mock
                    mock_stats = status_data.get("mock_statistics", {})
                    checks.append(("Statistiques mock pr√©sentes", bool(mock_stats)))
                    
                    passed_checks = sum(1 for _, passed in checks if passed)
                    total_checks = len(checks)
                    success = passed_checks >= (total_checks * 0.8)
                    
                    self.log_test(
                        "Publication Status Endpoint",
                        success,
                        f"Status: {passed_checks}/{total_checks} v√©rifications pass√©es",
                        {
                            "checks": dict(checks),
                            "status_data": status_data,
                            "mock_mode": mock_mode,
                            "platforms_available": platforms_available
                        }
                    )
                    
                    return success
                    
                else:
                    error_text = await response.text()
                    self.log_test(
                        "Publication Status Endpoint",
                        False,
                        f"Erreur HTTP {response.status}",
                        {"error": error_text}
                    )
                    return False
                    
        except Exception as e:
            self.log_test(
                "Publication Status Endpoint",
                False,
                f"Exception: {str(e)}"
            )
            return False
    
    async def test_publications_history_endpoint(self) -> bool:
        """Test 3: Endpoint /api/publications/history"""
        try:
            async with self.session.get(f"{BACKEND_URL}/publications/history?limit=20") as response:
                
                if response.status == 200:
                    result = await response.json()
                    
                    # V√©rifications
                    checks = []
                    
                    success_field = result.get("success", False)
                    publications = result.get("publications", [])
                    total = result.get("total", 0)
                    
                    checks.append(("R√©ponse success", success_field))
                    checks.append(("Publications pr√©sentes", isinstance(publications, list)))
                    checks.append(("Total coh√©rent", total >= 0))
                    
                    # Si des publications existent (apr√®s le test pr√©c√©dent)
                    if publications:
                        # V√©rifier la structure des publications
                        first_pub = publications[0]
                        expected_pub_fields = [
                            "id", "platform", "product_name", "status", 
                            "success", "mode", "created_at"
                        ]
                        
                        for field in expected_pub_fields:
                            checks.append((f"Publication champ {field}", field in first_pub))
                        
                        # V√©rifier que c'est bien du mock
                        mock_publications = [p for p in publications if p.get("mode") == "mock"]
                        checks.append(("Publications en mode mock", len(mock_publications) > 0))
                        
                        # V√©rifier les plateformes
                        platforms_found = set(p.get("platform") for p in publications)
                        expected_platforms = {"shopify", "woocommerce", "prestashop"}
                        platforms_match = len(platforms_found.intersection(expected_platforms)) >= 2
                        checks.append(("Plateformes attendues", platforms_match))
                    
                    passed_checks = sum(1 for _, passed in checks if passed)
                    total_checks = len(checks)
                    success = passed_checks >= (total_checks * 0.8)
                    
                    self.log_test(
                        "Publications History Endpoint",
                        success,
                        f"History: {passed_checks}/{total_checks} v√©rifications pass√©es, {len(publications)} publications trouv√©es",
                        {
                            "checks": dict(checks),
                            "publications_count": len(publications),
                            "total": total,
                            "sample_publication": publications[0] if publications else None
                        }
                    )
                    
                    return success
                    
                else:
                    error_text = await response.text()
                    self.log_test(
                        "Publications History Endpoint",
                        False,
                        f"Erreur HTTP {response.status}",
                        {"error": error_text}
                    )
                    return False
                    
        except Exception as e:
            self.log_test(
                "Publications History Endpoint",
                False,
                f"Exception: {str(e)}"
            )
            return False
    
    async def test_scraping_simulation(self) -> bool:
        """Test 4: Simulation de scraping avec datasets et proxies mock"""
        try:
            # Test indirect via g√©n√©ration (le scraping est int√©gr√©)
            request_data = {
                "product_name": "iPhone 15 Pro Test",
                "product_description": "Test scraping simulation avec datasets configur√©s",
                "category": "Electronics",
                "generate_image": False,
                "number_of_images": 0,
                "language": "fr"
            }
            
            headers = {"Authorization": f"Bearer {self.auth_token}"}
            
            async with self.session.post(
                f"{BACKEND_URL}/generate-sheet",
                json=request_data,
                headers=headers
            ) as response:
                
                if response.status == 200:
                    result = await response.json()
                    
                    # V√©rifications du scraping
                    checks = []
                    
                    # 1. V√©rifier que les donn√©es scrap√©es sont utilis√©es
                    seo_tags = result.get("seo_tags", [])
                    price_suggestions = result.get("price_suggestions", "")
                    marketing_description = result.get("marketing_description", "")
                    
                    checks.append(("Tags SEO g√©n√©r√©s", len(seo_tags) >= 5))
                    checks.append(("Suggestions prix pr√©sentes", bool(price_suggestions)))
                    checks.append(("Description enrichie", len(marketing_description) > 100))
                    
                    # 2. V√©rifier les m√©tadonn√©es de scraping (si disponibles)
                    seo_tags_source = result.get("seo_tags_source", "unknown")
                    checks.append(("Source SEO identifi√©e", seo_tags_source != "unknown"))
                    
                    # 3. V√©rifier la qualit√© des donn√©es (r√©alisme)
                    # Les datasets mock doivent produire des donn√©es coh√©rentes
                    realistic_keywords = any(
                        keyword.lower() in ["premium", "qualit√©", "innovation", "design", "performance"]
                        for keyword in seo_tags
                    )
                    checks.append(("Mots-cl√©s r√©alistes", realistic_keywords))
                    
                    # 4. V√©rifier que le scraping n'a pas fait d'appels r√©seau r√©els
                    # (Indirect - pas d'erreurs de timeout/r√©seau)
                    generation_time = result.get("generation_time", 0)
                    reasonable_time = generation_time < 60  # Moins de 60 secondes
                    checks.append(("Temps g√©n√©ration raisonnable", reasonable_time))
                    
                    passed_checks = sum(1 for _, passed in checks if passed)
                    total_checks = len(checks)
                    success = passed_checks >= (total_checks * 0.7)
                    
                    self.log_test(
                        "Scraping Simulation",
                        success,
                        f"Scraping: {passed_checks}/{total_checks} v√©rifications pass√©es",
                        {
                            "checks": dict(checks),
                            "seo_tags_count": len(seo_tags),
                            "seo_tags_source": seo_tags_source,
                            "generation_time": generation_time,
                            "sample_seo_tags": seo_tags[:5]
                        }
                    )
                    
                    return success
                    
                else:
                    error_text = await response.text()
                    self.log_test(
                        "Scraping Simulation",
                        False,
                        f"Erreur HTTP {response.status}",
                        {"error": error_text}
                    )
                    return False
                    
        except Exception as e:
            self.log_test(
                "Scraping Simulation",
                False,
                f"Exception: {str(e)}"
            )
            return False
    
    async def run_all_tests(self) -> Dict[str, Any]:
        """Ex√©cute tous les tests"""
        print("üöÄ D√âMARRAGE DES TESTS - SYST√àME DE PUBLICATION MOCK ECOMSIMPLY")
        print("=" * 80)
        
        # Setup
        setup_success = await self.setup_test_user()
        if not setup_success:
            return {"success": False, "error": "√âchec setup utilisateur"}
        
        # Tests principaux
        test_functions = [
            ("Test 1: G√©n√©ration + Publication Auto", self.test_generate_sheet_with_auto_publish),
            ("Test 2: Status Publication", self.test_publication_status_endpoint),
            ("Test 3: Historique Publications", self.test_publications_history_endpoint),
            ("Test 4: Simulation Scraping", self.test_scraping_simulation)
        ]
        
        results = []
        for test_name, test_func in test_functions:
            print(f"\nüìã {test_name}")
            print("-" * 50)
            
            try:
                result = await test_func()
                results.append(result)
            except Exception as e:
                print(f"‚ùå ERREUR CRITIQUE: {str(e)}")
                results.append(False)
        
        # R√©sum√© final
        print("\n" + "=" * 80)
        print("üìä R√âSUM√â DES TESTS")
        print("=" * 80)
        
        passed_tests = sum(1 for r in results if r)
        total_tests = len(results)
        success_rate = (passed_tests / total_tests) * 100 if total_tests > 0 else 0
        
        print(f"‚úÖ Tests r√©ussis: {passed_tests}/{total_tests} ({success_rate:.1f}%)")
        
        # D√©tail des r√©sultats
        for i, (test_name, _) in enumerate(test_functions):
            status = "‚úÖ PASS" if results[i] else "‚ùå FAIL"
            print(f"   {status} {test_name}")
        
        # Validation globale
        overall_success = success_rate >= 75  # 75% minimum
        
        if overall_success:
            print(f"\nüéâ VALIDATION GLOBALE: SUCC√àS")
            print("Le syst√®me de publication mock ECOMSIMPLY fonctionne correctement!")
            print("‚úÖ √âtapes 1-3 de la roadmap valid√©es:")
            print("   - Couches d'abstraction + mocks")
            print("   - Pipeline g√©n√©ration ‚Üí publication mock")
            print("   - Scraping en simulation contr√¥l√©e")
        else:
            print(f"\n‚ö†Ô∏è VALIDATION GLOBALE: √âCHEC PARTIEL")
            print("Certains composants n√©cessitent des corrections.")
        
        return {
            "success": overall_success,
            "passed_tests": passed_tests,
            "total_tests": total_tests,
            "success_rate": success_rate,
            "test_results": self.test_results
        }

async def main():
    """Point d'entr√©e principal"""
    async with MockPublicationTester() as tester:
        results = await tester.run_all_tests()
        
        # Code de sortie
        exit_code = 0 if results["success"] else 1
        sys.exit(exit_code)

if __name__ == "__main__":
    asyncio.run(main())